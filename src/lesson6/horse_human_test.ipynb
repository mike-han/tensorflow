{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94882989-d85b-40ba-8b7c-fc458071687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112da926-ce1d-4fec-bc66-46b8e460e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipfile.ZipFile\n",
    "# os.path.exists, shutil.rmtree, os.makedirs\n",
    "# random.sample, copyfile(this_file, destination)\n",
    "# optimizer=RMSprop, ImageDataGenerator(rescale=1.0/255.)\n",
    "# acc, val_acc, loss, val_loss, plt.plot, plt.title, plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847a573-12bf-4964-afff-b0f8fa7d7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipRef = zipfile.ZipFile('/tmp/horse-or-human.zip', 'r')\n",
    "zipRef.extractall('/tmp/horse_or_human/')\n",
    "zipRef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7c9a9-e7ef-41db-8651-50f25e77ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_directory(path):\n",
    "    if(os.path.exists(path)):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "\n",
    "source_human_path = '/tmp/horse_or_human/humans/'\n",
    "train_human_path = '/tmp/horses_v_humans/training/humans/'\n",
    "test_human_path = '/tmp/horses_v_humans/testing/humans/'\n",
    "\n",
    "source_horse_path = '/tmp/horse_or_human/horses/'\n",
    "train_horse_path = '/tmp/horses_v_humans/training/horses/'\n",
    "test_horse_path = '/tmp/horses_v_humans/testing/horses/'\n",
    "\n",
    "create_directory(train_human_path)\n",
    "create_directory(test_human_path)\n",
    "\n",
    "create_directory(train_horse_path)\n",
    "create_directory(test_horse_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310542a0-9fb2-4d69-ab9a-5609395bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def split_data(source, train_path, test_path, size = 0.9):\n",
    "    files = []\n",
    "    for filename in os.listdir(source):\n",
    "        this_file = source + filename\n",
    "        if os.path.getsize(this_file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + ' is zero length, so ignoring.')\n",
    "    \n",
    "    shuffled_files = random.sample(files, len(files))\n",
    "    train_files = shuffled_files[0: int(len(shuffled_files) * size)]\n",
    "    test_files = shuffled_files[-(len(shuffled_files) - len(train_files)):]\n",
    "    \n",
    "    for filename in train_files:\n",
    "        this_file = source + filename\n",
    "        target_file = train_path + filename\n",
    "        copyfile(this_file, target_file)\n",
    "    \n",
    "    for filename in test_files:\n",
    "        this_file = source + filename\n",
    "        target_file = test_path + filename\n",
    "        copyfile(this_file, target_file)\n",
    "\n",
    "split_data(source_human_path, train_human_path, test_human_path, 0.9)\n",
    "split_data(source_horse_path, train_horse_path, test_horse_path, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e55d04-9a94-4aab-8b9b-5357334db86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_horse_names = os.listdir(train_horse_path)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_human_path)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c92b5-b7cb-4778-857d-f7f158f3aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_path, fname) \n",
    "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_path, fname) \n",
    "                for fname in train_human_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91c42a-d55e-47d8-89bd-911dcb9efe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "train_gen = train_datagen.flow_from_directory('/tmp/horses_v_humans/training/', batch_size=100, class_mode='binary', target_size=(150,150))\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_gen = train_datagen.flow_from_directory('/tmp/horses_v_humans/testing/', batch_size=100, class_mode='binary', target_size=(150,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b24bb-0f7d-407c-88e8-d14ba1417faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "# The second convolution\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "# The third convolution\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "# The fourth convolution\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "# The fifth convolution\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "    \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=RMSprop(0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edbe70-c394-44d2-9971-aae9ce2ea1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen, epochs=5, verbose=1, validation_data=test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e6f4d-dad0-462d-ac79-61511957b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', 'Train accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', 'Validation accuracy')\n",
    "plt.title('Train - Validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss, 'r', 'Train loss')\n",
    "plt.plot(epochs, val_loss, 'b', 'Validation loss')\n",
    "plt.title('Train - Validation loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd81fa1-9ce2-4280-909c-d90b9fb60820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "img1 = image.load_img('/tmp/horse_or_human/horses/horse01-0.png', target_size = (img_width, img_height))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1, axis = 0)\n",
    "\n",
    "img2 = image.load_img('/tmp/horse_or_human/humans/human01-00.png', target_size = (img_width, img_height))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2, axis = 0)\n",
    "\n",
    "print(model.predict(img1))\n",
    "print(model.predict(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dfa2fe-8808-4d8b-b38e-c2a367e42b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(300, 300))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "  else:\n",
    "    print(fn + \" is a horse\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09996eb-9636-4a53-829c-ce8479652ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "horse_img_files = [os.path.join(train_horse_path, f) for f in train_horse_names]\n",
    "human_img_files = [os.path.join(train_human_path, f) for f in train_human_names]\n",
    "\n",
    "img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(150,150))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x /= 255\n",
    "\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737125c5-3cb9-41f3-8257-39030bf59366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
