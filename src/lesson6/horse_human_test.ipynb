{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94882989-d85b-40ba-8b7c-fc458071687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112da926-ce1d-4fec-bc66-46b8e460e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipfile.ZipFile\n",
    "# os.path.exists, shutil.rmtree, os.makedirs\n",
    "# random.sample, copyfile(this_file, destination)\n",
    "# optimizer=RMSprop, ImageDataGenerator(rescale=1.0/255.)\n",
    "# acc, val_acc, loss, val_loss, plt.plot, plt.title, plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847a573-12bf-4964-afff-b0f8fa7d7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipRef = zipfile.ZipFile('/tmp/horse-or-human.zip', 'r')\n",
    "zipRef.extractall('/tmp/horse_or_human/')\n",
    "zipRef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7c9a9-e7ef-41db-8651-50f25e77ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_directory(path):\n",
    "    if(os.path.exists(path)):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "\n",
    "source_human_path = '/tmp/horse_or_human/humans/'\n",
    "train_human_path = '/tmp/horses_v_humans/training/humans/'\n",
    "test_human_path = '/tmp/horses_v_humans/testing/humans/'\n",
    "\n",
    "source_horse_path = '/tmp/horse_or_human/horses/'\n",
    "train_horse_path = '/tmp/horses_v_humans/training/horses/'\n",
    "test_horse_path = '/tmp/horses_v_humans/testing/horses/'\n",
    "\n",
    "create_directory(train_human_path)\n",
    "create_directory(test_human_path)\n",
    "\n",
    "create_directory(train_horse_path)\n",
    "create_directory(test_horse_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310542a0-9fb2-4d69-ab9a-5609395bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def split_data(source, train_path, test_path, size = 0.9):\n",
    "    files = []\n",
    "    for filename in os.listdir(source):\n",
    "        this_file = source + filename\n",
    "        if os.path.getsize(this_file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + ' is zero length, so ignoring.')\n",
    "    \n",
    "    shuffled_files = random.sample(files, len(files))\n",
    "    train_files = shuffled_files[0: int(len(shuffled_files) * size)]\n",
    "    test_files = shuffled_files[-(len(shuffled_files) - len(train_files)):]\n",
    "    \n",
    "    for filename in train_files:\n",
    "        this_file = source + filename\n",
    "        target_file = train_path + filename\n",
    "        copyfile(this_file, target_file)\n",
    "    \n",
    "    for filename in test_files:\n",
    "        this_file = source + filename\n",
    "        target_file = test_path + filename\n",
    "        copyfile(this_file, target_file)\n",
    "\n",
    "split_data(source_human_path, train_human_path, test_human_path, 0.9)\n",
    "split_data(source_horse_path, train_horse_path, test_horse_path, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91c42a-d55e-47d8-89bd-911dcb9efe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "train_gen = train_datagen.flow_from_directory('/tmp/horses_v_humans/training/', batch_size=100, class_mode='binary', target_size=(150,150))\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_gen = train_datagen.flow_from_directory('/tmp/horses_v_humans/testing/', batch_size=100, class_mode='binary', target_size=(150,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b24bb-0f7d-407c-88e8-d14ba1417faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=RMSprop(0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edbe70-c394-44d2-9971-aae9ce2ea1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen, epochs=5, verbose=1, validation_data=test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e6f4d-dad0-462d-ac79-61511957b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', 'Train accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', 'Validation accuracy')\n",
    "plt.title('Train - Validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss, 'r', 'Train loss')\n",
    "plt.plot(epochs, val_loss, 'b', 'Validation loss')\n",
    "plt.title('Train - Validation loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dd81fa1-9ce2-4280-909c-d90b9fb60820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "img1 = image.load_img('/tmp/horse_or_human/horses/horse01-0.png', target_size = (img_width, img_height))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1, axis = 0)\n",
    "\n",
    "img2 = image.load_img('/tmp/horse_or_human/humans/human01-00.png', target_size = (img_width, img_height))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2, axis = 0)\n",
    "\n",
    "print(model.predict(img1))\n",
    "print(model.predict(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be3510-0e72-46a4-b86f-b3e251bf6387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3166b915-549d-4651-8c26-629cd8f83e6a\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-3166b915-549d-4651-8c26-629cd8f83e6a\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(150, 150))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "  else:\n",
    "    print(fn + \" is a horse\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
