{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([[1], [2], [3]])\n",
    "for element in dataset:\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(8)\n",
    "dataset = dataset.batch(3, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [\n",
    "  [0], [1, 2, 3, 4], [5, 6, 7],\n",
    "  [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64, output_shapes=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.bucket_by_sequence_length(\n",
    "        element_length_func=lambda elem: tf.shape(elem)[0],\n",
    "        bucket_boundaries=[3, 5],\n",
    "        bucket_batch_sizes=[2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "dataset = dataset.map(lambda x: x**2)\n",
    "dataset = dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\n",
    "            tf.data.Dataset.from_tensors(\"bar\").repeat(),\n",
    "            tf.data.Dataset.from_tensors(\"baz\").repeat()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_dataset = tf.data.Dataset.range(3).repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(choice_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
    "b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
    "ds = a.concatenate(b)\n",
    "list(ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.enumerate(start=5)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.enumerate(start=3)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: x < 3)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(x):\n",
    "  return tf.math.equal(x, 1)\n",
    "  \n",
    "dataset = dataset.filter(filter_fn)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(\n",
    "    lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "  ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
    "  yield 42, ragged_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "         tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a 1D tensor produces scalar tensor elements.\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "list(dataset.as_numpy_iterator())\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
    "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
    "\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
    "                                [[2, 1], [1, 2]],\n",
    "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_labels = tf.constant([['A', 'A'],\n",
    "                              ['B', 'B'],\n",
    "                              ['A', 'B']], shape=(3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
    "for element in dataset.as_numpy_iterator():\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.constant([1,2,3])\n",
    "dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
    "list(dataset.as_numpy_iterator())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(feature):\n",
    "  # ... the raw_feature is preprocessed as per the use-case\n",
    "  return feature\n",
    "\n",
    "raw_features = [1, 2, 3, 4]  # input batch of BATCH_SIZE elements.\n",
    "dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
    "          .map(preprocessing_fn, num_parallel_calls=4)\n",
    "          .batch(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "window_size = 5\n",
    "key_func = lambda x: x%2\n",
    "reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
    "dataset = dataset.group_by_window(\n",
    "          key_func=key_func,\n",
    "          reduce_func=reduce_func,\n",
    "          window_size=window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "list(dataset.as_numpy_iterator())\n",
    "dataset = dataset.group_by_window(key_func=lambda x: x, reduce_func=lambda _, ds: ds.batch(2), window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1], dtype=int32),\n",
       " array([2, 2], dtype=int32),\n",
       " array([3, 3, 3], dtype=int32),\n",
       " array([4, 4, 4, 4], dtype=int32)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = (tf.data.Dataset\n",
    "     .range(1, 5, output_type=tf.int32)\n",
    "     .map(lambda x: tf.fill([x], x)))\n",
    "list(A.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[ 1, -1],\n",
       "         [ 2,  2]], dtype=int32),\n",
       "  array([[ 1, -1],\n",
       "         [ 2,  2]], dtype=int32)),\n",
       " (array([[ 3,  3,  3, -1],\n",
       "         [ 4,  4,  4,  4]], dtype=int32),\n",
       "  array([[ 3,  3,  3, -1],\n",
       "         [ 4,  4,  4,  4]], dtype=int32))]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
    "list(E.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 0],\n",
       "        [2, 2]], dtype=int32),\n",
       " array([[3, 3, 3, 0],\n",
       "        [4, 4, 4, 4]], dtype=int32)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.padded_batch(2)\n",
    "list(B.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1, -1, -1, -1, -1],\n",
       "        [ 2,  2, -1, -1, -1]], dtype=int32),\n",
       " array([[ 3,  3,  3, -1, -1],\n",
       "        [ 4,  4,  4,  4, -1]], dtype=int32)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
    "list(C.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1, 2, 3], dtype=int32), array([10], dtype=int32)),\n",
       " (array([4, 5], dtype=int32), array([11, 12], dtype=int32))]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = [([1, 2, 3], [10]),\n",
    "            ([4, 5], [11, 12])]\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: iter(elements), (tf.int32, tf.int32))\n",
    "\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[ 1,  2,  3, -1],\n",
       "         [ 4,  5, -1, -1]], dtype=int32),\n",
       "  array([[ 10, 100],\n",
       "         [ 11,  12]], dtype=int32))]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.padded_batch(2,\n",
    "    padded_shapes=([4], [None]),\n",
    "    padding_values=(-1, 100))\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "dataset = dataset.prefetch(2)\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.random(seed=4).take(10)\n",
    "ds2 = tf.data.Dataset.random(seed=4).take(10)\n",
    "print(list(ds2.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "dataset = dataset.repeat(2)\n",
    "print(list(dataset.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.skip(7)\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]), array([1, 2]), array([1, 2, 3, 4])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
    "dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.unbatch()\n",
    "list(dataset.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 37]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
    "dataset = dataset.unique()\n",
    "sorted(list(dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 5]\n",
      "[6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 15:53:23.714519: W tensorflow/core/framework/dataset.cc:768] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3)\n",
    "for window in dataset:\n",
    "  print(list(window.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8639f22e1530ee2a5f2548bc0245ffed892f59880c37de02f243da87cdc45584"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
